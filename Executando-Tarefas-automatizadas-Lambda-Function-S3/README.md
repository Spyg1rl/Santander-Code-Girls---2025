# Executando-Tarefas-automatizadas-Lambda-Function-S3
<img width="60" height="160" alt="image" src="https://github.com/user-attachments/assets/d759c827-ea61-400c-a461-a5e5a6953dba" />
 Este reposit√≥rio foi criado como parte dos estudos e desafios do Santander Code Girls - Executando Tarefas Automatizadas com Lambda Function e S3.
 

üöÄ Projeto DIO: O Poder da Automa√ß√£o com AWS Lambda e S3
Neste laborat√≥rio, mergulhei no ecossistema da AWS para construir um pipeline de automa√ß√£o de tarefas . O objetivo n√£o foi apenas aprender sobre servi√ßos isolados, mas entender como a combina√ß√£o inteligente de Amazon S3 e AWS Lambda pode criar solu√ß√µes que reagem a eventos em tempo real, de forma escal√°vel e sem a necessidade de gerenciamento de servidores.

As Pe√ßas do Quebra-Cabe√ßa
Para construir essa automa√ß√£o, utilizamos dois servi√ßos fundamentais da AWS, cada um com um papel muito claro:

1. Amazon S3: O "Dep√≥sito Inteligente" (O Gatilho)
Muitos pensam no Amazon S3 (Simple Storage Service) apenas como um "HD na nuvem". No entanto, neste projeto, utilizamos como um servi√ßo de armazenamento ativo .

Ele n√£o √© apenas um local para salvar arquivos (objetos) de forma segura e dur√°vel. Sua verdadeira for√ßa para a automa√ß√£o √© sua capacidade de emitir eventos . O S3 pode, literalmente, "avisar" outros servi√ßos da AWS sempre que algo acontece em um bucket , como:

Um novo arquivo foi carregado ( PUT).
Um arquivo foi exclu√≠do ( DELETE).
Um arquivo foi modificado.
No nosso desafio, o S3 atua como o ponto de partida , o gatilho que inicia todo o processo.
Exemplo Pr√°tico: Imagine um bucket S3 configurado para receber logs de diversas aplica√ß√µes. Se algu√©m verificar manualmente essa pasta, o S3 pode disparar nossa automa√ß√£o no segundo exato em que um novo log chega.

2. AWS Lambda: O "Funcion√°rio Sob Demanda" (A A√ß√£o)
Se o S3 √© o gatilho, o AWS Lambda √© a a√ß√£o . Ele √© o c√©rebro da nossa opera√ß√£o e a ess√™ncia da computa√ß√£o serverless .

A magia do Lambda √© simples: voc√™ s√≥ se preocupa com o c√≥digo . N√£o h√° servidores para provisionar, atualizar ou escalar.

Ele "dorme" (sem custo) at√© ser invocado por um evento.
Quando o S3 (ou qualquer outro gatilho) o chama, ele "acorda" instantaneamente, executa a l√≥gica que programamos e volta a "dormir".
Ele escala automaticamente. Se 1000 arquivos chegarem ao S3 ao mesmo tempo, a AWS provisionar√° 1000 inst√¢ncias da fun√ß√£o para process√°-los em paralelo.
Exemplo Pr√°tico: Continuando o exemplo dos logs, assim que o S3 avisa sobre um novo log, o Lambda √© acionado. Nossa fun√ß√£o poderia, ent√£o, ler o log, procurar por mensagens de "ERRO", e,     se encontrar, enviar uma notifica√ß√£o para um hor√°rio de suporte via Slack ou SNS.
	 
A M√°gica da Integra√ß√£o: S3 + Lambda na Pr√°tica
O verdadeiro poder explorado neste desafio est√° na conex√£o entre esses dois servi√ßos. Criamos um pipeline orientado a eventos (orientado para eventos) cl√°ssico:

  
1- Evento: Um usu√°rio (ou sistema) faz o upload de um arquivo (ex: dados.csv) para um bucket S3.
2- Gatilho: O S3 detecta o evento s3:ObjectCreated:*e envia uma notifica√ß√£o.
3- Invoca√ß√£o: O Lambda, que estava "escutando" esse tipo de evento, √© invocado, recebendo um JSON com todos os detalhes do arquivo (nome, local, tamanho, etc.).
4- Processamento: Nosso c√≥digo dentro do Lambda √© executado.

  Analisando o C√≥digo (Node.js)
  O "esqueleto" de uma fun√ß√£o Lambda que reage a um evento do S3 √© direto. O foco √© saber ‚Äúler‚Äù o evento que o S3 nos envia.
  
    // Importamos o SDK da AWS para, se necess√°rio, manipular outros servi√ßos
    const AWS = require('aws-sdk');
    const s3 = new AWS.S3();

    // O 'handler' √© o ponto de entrada da nossa fun√ß√£o
    exports.handler = async (event) => {
    
    // O 'event' √© o JSON enviado pelo S3. 
    // Precisamos "desempacotar" ele para achar o que nos interessa.
    const bucketName = event.Records[0].s3.bucket.name;
    const objectKey = event.Records[0].s3.object.key; // 'key' √© o nome/caminho do arquivo

    // Um log para vermos no CloudWatch o que recebemos
    console.log(`Novo arquivo detectado: ${objectKey} no bucket ${bucketName}`);

    //
    // √â AQUI QUE A L√ìGICA DE NEG√ìCIO ENTRA:
    //
    // * Poder√≠amos ler o conte√∫do do arquivo com s3.getObject().
    // * Se fosse uma imagem, poder√≠amos redimension√°-la.
    // * Se fosse um CSV, poder√≠amos validar os dados e inserir em um banco de dados.
    //

    // Retornamos uma resposta de sucesso
    return {
        statusCode: 200,
        body: JSON.stringify('Processamento conclu√≠do com sucesso!')
    };
    };

  
   Desafio proposto por Digital Innovation One - DIO
 

 
